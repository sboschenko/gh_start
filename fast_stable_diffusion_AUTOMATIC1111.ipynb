{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kV9o1Ni8GH"
      },
      "source": [
        "# **Colab Pro notebook from https://github.com/TheLastBen/fast-stable-diffusion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "Y9EBc437WDOs",
        "outputId": "0913f35e-2605-4fc8-e378-9d5dcc850d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c684efeff9ec40fb9bd004ede1843b00",
            "a24c736388444ff58305390cd620bd9a",
            "ad87e05eb9a34a20a3d2ca5567e033b4"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c684efeff9ec40fb9bd004ede1843b00"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Connect Google Drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "Shared_Drive = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Leave empty if you're not using a shared drive\n",
        "\n",
        "print(\"\u001b[0;33mConnecting...\")\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if Shared_Drive!=\"\" and os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  mainpth=\"Shareddrives/\"+Shared_Drive\n",
        "else:\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CFWtw-6EPrKi"
      },
      "outputs": [],
      "source": [
        "#@markdown # Install/Update AUTOMATIC1111 repo\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import time\n",
        "import base64\n",
        "import requests\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.parse import urlparse, parse_qs, unquote\n",
        "from tqdm import tqdm\n",
        "import six\n",
        "\n",
        "\n",
        "blsaphemy=base64.b64decode((\"ZWJ1aQ==\").encode('ascii')).decode('ascii')\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive\"):\n",
        "  print('\u001b[1;31mGdrive not connected, using temporary colab storage ...')\n",
        "  time.sleep(4)\n",
        "  mainpth=\"MyDrive\"\n",
        "  !mkdir -p /content/gdrive/$mainpth\n",
        "  Shared_Drive=\"\"\n",
        "\n",
        "if Shared_Drive!=\"\" and not os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  print('\u001b[1;31mShared drive not detected, using default MyDrive')\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "  fgitclone = \"git clone --depth 1\"\n",
        "  !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
        "  %mkdir -p /content/gdrive/$mainpth/sd\n",
        "  %cd /content/gdrive/$mainpth/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/cache/\n",
        "  os.environ['TRANSFORMERS_CACHE']=f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blsaphemy+\"/cache\"\n",
        "  os.environ['TORCH_HOME'] = f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blsaphemy+\"/cache\"\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/repositories\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy-assets /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/repositories/stable-diffusion-webui-assets\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/\n",
        "  !git reset --hard\n",
        "  !git checkout master\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZGV_5H4xrOSp"
      },
      "outputs": [],
      "source": [
        "#@markdown # Requirements\n",
        "\n",
        "print('\u001b[1;32mInstalling requirements...')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/\n",
        "  !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/A1111.txt\n",
        "  !dpkg -i *.deb\n",
        "  !pip uninstall wandb -y\n",
        "  if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stablediffusion'):\n",
        "    !tar -C /content/gdrive/$mainpth --zstd -xf sd_mrep.tar.zst\n",
        "  !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "  !rm *.deb | rm *.zst | rm *.txt\n",
        "  if not os.path.exists('gdrive/'+mainpth+'/sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
        "    %env CXXFLAGS=-std=c++14\n",
        "    !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n",
        "    !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n",
        "    %cd /content/gperftools\n",
        "    !patch -p1 < /content/Patch\n",
        "    !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
        "    !mkdir -p /content/gdrive/$mainpth/sd/libtcmalloc && cp .libs/libtcmalloc*.so* /content/gdrive/$mainpth/sd/libtcmalloc\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "    %cd /content\n",
        "    !rm *.tar.gz Patch && rm -r /content/gperftools\n",
        "  else:\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "\n",
        "  !pip install wandb==0.15.12 pydantic==1.10.2 controlnet_aux -qq\n",
        "  !pip install diffusers accelerate -U -qq\n",
        "  !rm -r /usr/local/lib/python3.11/dist-packages/tensorflow*\n",
        "  os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "  !sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' /usr/lib/python3.11/warnings.py\n",
        "  !sed -i 's@raise AttributeError(f\"module {module!r} has no attribute {name!r}\")@@g' /usr/local/lib/python3.11/dist-packages/jax/_src/deprecations.py\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p4wj_txjP3TC"
      },
      "outputs": [],
      "source": [
        "#@markdown # Model Download/Load\n",
        "\n",
        "import gdown\n",
        "from gdown.download import get_url_from_gdrive_confirmation\n",
        "import re\n",
        "\n",
        "Use_Temp_Storage = False #@param {type:\"boolean\"}\n",
        "#@markdown - If not, make sure you have enough space on your gdrive\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model_Version = \"SDXL\" #@param [\"SDXL\", \"1.5\", \"v1.5 Inpainting\", \"V2.1-768px\"]\n",
        "\n",
        "#@markdown Or\n",
        "PATH_to_MODEL = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Insert the full path of your custom model or to a folder containing multiple models\n",
        "\n",
        "#@markdown Or\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "def getsrc(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if parsed_url.netloc == 'civitai.com':\n",
        "        src='civitai'\n",
        "    elif parsed_url.netloc == 'drive.google.com':\n",
        "        src='gdrive'\n",
        "    elif parsed_url.netloc == 'huggingface.co':\n",
        "        src='huggingface'\n",
        "    else:\n",
        "        src='others'\n",
        "    return src\n",
        "\n",
        "src=getsrc(MODEL_LINK)\n",
        "\n",
        "def get_name(url, gdrive):\n",
        "    if not gdrive:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if \"Location\" in response.headers:\n",
        "            redirected_url = response.headers[\"Location\"]\n",
        "            quer = parse_qs(urlparse(redirected_url).query)\n",
        "            if \"response-content-disposition\" in quer:\n",
        "                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n",
        "                for vals in disp_val:\n",
        "                    if vals.strip().startswith(\"filename=\"):\n",
        "                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n",
        "                        return filenm.replace(\"\\\"\",\"\")\n",
        "    else:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n",
        "        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n",
        "        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n",
        "        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n",
        "        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n",
        "        filenm = re.search('attachment; filename=\"(.*?)\"', content_disposition).groups()[0]\n",
        "        return filenm\n",
        "\n",
        "\n",
        "def dwn(url, dst, msg):\n",
        "    file_size = None\n",
        "    req = Request(url, headers={\"User-Agent\": \"torch.hub\"})\n",
        "    u = urlopen(req)\n",
        "    meta = u.info()\n",
        "    if hasattr(meta, 'getheaders'):\n",
        "        content_length = meta.getheaders(\"Content-Length\")\n",
        "    else:\n",
        "        content_length = meta.get_all(\"Content-Length\")\n",
        "    if content_length is not None and len(content_length) > 0:\n",
        "        file_size = int(content_length[0])\n",
        "\n",
        "    with tqdm(total=file_size, disable=False, mininterval=0.5,\n",
        "              bar_format=msg+' |{bar:20}| {percentage:3.0f}%') as pbar:\n",
        "        with open(dst, \"wb\") as f:\n",
        "            while True:\n",
        "                buffer = u.read(8192)\n",
        "                if len(buffer) == 0:\n",
        "                    break\n",
        "                f.write(buffer)\n",
        "                pbar.update(len(buffer))\n",
        "            f.close()\n",
        "\n",
        "\n",
        "def sdmdls(ver, Use_Temp_Storage):\n",
        "\n",
        "  if ver=='1.5':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v1-5-pruned-emaonly.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors'\n",
        "  elif ver=='V2.1-768px':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v2-1_768-ema-pruned.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/v2-1_768-ema-pruned.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors'\n",
        "  elif ver=='v1.5 Inpainting':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd-v1-5-inpainting.ckpt'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt'\n",
        "  elif ver=='SDXL':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd_xl_base_1.0.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/sd_xl_base_1.0.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors'\n",
        "\n",
        "  if not os.path.exists(model):\n",
        "    !gdown --fuzzy -O $model $link\n",
        "    if os.path.exists(model):\n",
        "      clear_output()\n",
        "      inf('\\u2714 Done','success', '50px')\n",
        "    else:\n",
        "      inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "  else:\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists','primary', '300px')\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "if (PATH_to_MODEL !=''):\n",
        "  if os.path.exists(str(PATH_to_MODEL)):\n",
        "    inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  else:\n",
        "      while not os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2718 Wrong path, use the colab file explorer to copy the path : ','danger', \"400px\")\n",
        "        PATH_to_MODEL=input()\n",
        "      if os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2714 Using the custom model.','success', '200px')\n",
        "\n",
        "  model=PATH_to_MODEL\n",
        "\n",
        "elif MODEL_LINK != \"\":\n",
        "\n",
        "      if src=='civitai':\n",
        "         modelname=get_name(MODEL_LINK, False)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            dwn(MODEL_LINK, model, 'Downloading the custom model')\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      elif src=='gdrive':\n",
        "         modelname=get_name(MODEL_LINK, True)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      else:\n",
        "         modelname=os.path.basename(MODEL_LINK)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '700px')\n",
        "\n",
        "      if os.path.exists(model) and os.path.getsize(model) > 1810671599:\n",
        "        inf('\\u2714 Model downloaded, using the custom model.','success', '300px')\n",
        "      else:\n",
        "        !rm model\n",
        "        inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "else:\n",
        "  model=sdmdls(Model_Version, Use_Temp_Storage)\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "Svx6Hx0iUPd1",
        "outputId": "15231197-9aa0-4dd1-fe47-cb38ff07883c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can only concatenate str (not \"NoneType\") to str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9e3f4abf53ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mloramodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloramodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdwn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLoRA_LINK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloramodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Downloading the LoRA model '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
          ]
        }
      ],
      "source": [
        "#@markdown # Download LoRA\n",
        "\n",
        "LoRA_LINK = \"https://civitai.com/api/download/models/1355026?type=Model&format=SafeTensor\" #@param {type:\"string\"}\n",
        "\n",
        "if LoRA_LINK == \"\":\n",
        "  inf('\\u2714 Nothing to do','primary', '200px')\n",
        "else:\n",
        "  os.makedirs('/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Lora', exist_ok=True)\n",
        "\n",
        "  src=getsrc(LoRA_LINK)\n",
        "\n",
        "  if src=='civitai':\n",
        "      modelname=get_name(LoRA_LINK, False)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        dwn(LoRA_LINK, loramodel, 'Downloading the LoRA model '+modelname)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "  elif src=='gdrive':\n",
        "      modelname=get_name(LoRA_LINK, True)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "  else:\n",
        "      modelname=os.path.basename(LoRA_LINK)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "\n",
        "  if os.path.exists(loramodel) :\n",
        "    inf('\\u2714 LoRA downloaded','success', '200px')\n",
        "  else:\n",
        "    inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zC3Rz1b2TBcB"
      },
      "outputs": [],
      "source": [
        "#@markdown # ControlNet\n",
        "from torch.hub import download_url_to_file\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from subprocess import run\n",
        "\n",
        "XL_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"Sketch\", \"OpenPose\", \"Recolor\"]\n",
        "\n",
        "v1_Model = \"None\" #@param [ \"None\", \"All (21GB)\", \"Canny\", \"Depth\", \"Lineart\", \"MLSD\", \"Normal\", \"OpenPose\", \"Scribble\", \"Seg\", \"ip2p\", \"Shuffle\", \"Inpaint\", \"Softedge\", \"Lineart_Anime\", \"Tile\", \"T2iadapter_Models\"]\n",
        "\n",
        "v2_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"HED\", \"OpenPose\", \"Scribble\"]\n",
        "\n",
        "#@markdown - Download/update ControlNet extension and its models\n",
        "\n",
        "def download(url, model_dir):\n",
        "\n",
        "    filename = os.path.basename(urlparse(url).path)\n",
        "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
        "    if not os.path.exists(pth):\n",
        "        print('Downloading: '+os.path.basename(url))\n",
        "        download_url_to_file(url, pth, hash_prefix=None, progress=True)\n",
        "    else:\n",
        "      print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
        "\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_canny_mid.safetensors'\n",
        "Depth='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_depth_mid.safetensors'\n",
        "Sketch='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/sai_xl_sketch_256lora.safetensors'\n",
        "OpenPose='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/thibaud_xl_openpose_256lora.safetensors'\n",
        "Recolor='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/sai_xl_recolor_128lora.safetensors'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/extensions\n",
        "  if not os.path.exists('sd-w'+blsaphemy+'-controlnet'):\n",
        "    !git clone https://github.com/Mikubill/sd-w$blsaphemy-controlnet.git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd sd-w$blsaphemy-controlnet\n",
        "    !git reset --hard\n",
        "    !git pull\n",
        "    %cd /content\n",
        "\n",
        "mdldir='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/extensions/sd-w'+blsaphemy+'-controlnet/models'\n",
        "for filename in os.listdir(mdldir):\n",
        "  if \"_sd14v1\" in filename:\n",
        "    renamed = re.sub(\"_sd14v1\", \"-fp16\", filename)\n",
        "    os.rename(os.path.join(mdldir, filename), os.path.join(mdldir, renamed))\n",
        "\n",
        "!wget -q -O CN_models.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models.txt\n",
        "!wget -q -O CN_models_v2.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_v2.txt\n",
        "!wget -q -O CN_models_XL.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_XL.txt\n",
        "\n",
        "\n",
        "with open(\"CN_models.txt\", 'r') as f:\n",
        "  mdllnk = f.read().splitlines()\n",
        "with open(\"CN_models_v2.txt\", 'r') as d:\n",
        "  mdllnk_v2 = d.read().splitlines()\n",
        "with open(\"CN_models_XL.txt\", 'r') as d:\n",
        "  mdllnk_XL = d.read().splitlines()\n",
        "\n",
        "!rm CN_models.txt CN_models_v2.txt CN_models_XL.txt\n",
        "\n",
        "\n",
        "if XL_Model == \"All\":\n",
        "  for lnk_XL in mdllnk_XL:\n",
        "      download(lnk_XL, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif XL_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[XL_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth'\n",
        "Depth='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth'\n",
        "Lineart='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart.pth'\n",
        "MLSD='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd.pth'\n",
        "Normal='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae.pth'\n",
        "OpenPose='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth'\n",
        "Scribble='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble.pth'\n",
        "Seg='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg.pth'\n",
        "ip2p='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p.pth'\n",
        "Shuffle='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle.pth'\n",
        "Inpaint='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint.pth'\n",
        "Softedge='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge.pth'\n",
        "Lineart_Anime='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime.pth'\n",
        "Tile='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  cfgnames=[os.path.basename(url).split('.')[0]+'.yaml' for url in mdllnk_v2]\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/extensions/sd-w$blsaphemy-controlnet/models\n",
        "  for name in cfgnames:\n",
        "      run(['cp', 'cldm_v21.yaml', name])\n",
        "  %cd /content\n",
        "\n",
        "if v1_Model == \"All (21GB)\":\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif v1_Model == \"T2iadapter_Models\":\n",
        "  mdllnk=list(filter(lambda x: 't2i' in x, mdllnk))\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif v1_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "\n",
        "else:\n",
        "  download(globals()[v1_Model], mdldir)\n",
        "  clear_output()\n",
        "\n",
        "Canny='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors'\n",
        "Depth='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors'\n",
        "HED='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors'\n",
        "OpenPose='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openposev2.safetensors'\n",
        "Scribble='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors'\n",
        "\n",
        "\n",
        "if v2_Model == \"All\":\n",
        "  for lnk_v2 in mdllnk_v2:\n",
        "      download(lnk_v2, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif v2_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[v2_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "  #@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "PjzwxTkPSPHf",
        "outputId": "15e5f2a0-821b-490a-ad30-46d389e1e67e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth\" to /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/hub/checkpoints/checkpoint_liberty_with_aug.pth\n",
            "100% 5.10M/5.10M [00:00<00:00, 87.0MB/s]\n",
            "ControlNet preprocessor location: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads\n",
            "2025-02-20 08:41:35,891 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet v1.1.455\n",
            "Calculating sha256 for /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd_xl_base_1.0.safetensors: 2025-02-20 08:41:37,543 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "Running on public URL: https://b6accf89fbbbae2638.gradio.live\n",
            "\u001b[32m✔ Connected\n",
            "Startup time: 33.4s (launcher: 0.2s, import torch: 13.8s, import gradio: 3.4s, setup paths: 3.4s, initialize shared: 0.4s, other imports: 3.0s, list SD models: 0.2s, load scripts: 4.6s, initialize extra networks: 0.2s, create ui: 2.4s, gradio launch: 1.0s, add APIs: 0.5s).\n",
            "31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b\n",
            "Loading weights [31e35c80fc] from /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/sd_xl_base_1.0.safetensors\n",
            "Creating model from config: /content/gdrive/MyDrive/sd/stablediffusion/generative-models/configs/inference/sd_xl_base.yaml\n",
            "vocab.json100% 961k/961k [00:00<00:00, 4.34MB/s]\n",
            "merges.txt100% 525k/525k [00:00<00:00, 2.42MB/s]\n",
            "special_tokens_map.json100% 389/389 [00:00<00:00, 3.41MB/s]\n",
            "tokenizer_config.json100% 905/905 [00:00<00:00, 5.89MB/s]\n",
            "config.json100% 4.52k/4.52k [00:00<00:00, 40.6MB/s]\n",
            "Applying attention optimization: xformers... done.\n",
            "Model loaded in 89.3s (calculate hash: 50.8s, load weights from disk: 3.0s, create model: 2.6s, apply weights to model: 31.4s, load textual inversion embeddings: 0.2s, calculate empty prompt: 1.0s).\n",
            "Downloading VAEApprox model to: /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/VAE-approx/vaeapprox-sdxl.pt\n",
            "100% 209k/209k [00:00<00:00, 11.1MB/s]\n",
            "100% 20/20 [00:04<00:00,  4.25it/s]\n",
            "100% 20/20 [00:04<00:00,  4.90it/s]\n",
            "100% 20/20 [00:04<00:00,  4.92it/s]\n",
            "100% 20/20 [00:04<00:00,  4.86it/s]\n",
            "100% 20/20 [00:04<00:00,  4.84it/s]\n",
            "100% 20/20 [00:04<00:00,  4.86it/s]\n",
            "100% 20/20 [00:08<00:00,  2.46it/s]\n",
            "100% 20/20 [00:08<00:00,  2.47it/s]\n",
            "100% 20/20 [00:08<00:00,  2.46it/s]\n",
            "100% 20/20 [00:08<00:00,  2.45it/s]\n",
            "100% 20/20 [00:08<00:00,  2.45it/s]\n",
            "100% 20/20 [00:08<00:00,  2.43it/s]\n",
            "100% 20/20 [00:08<00:00,  2.38it/s]\n",
            "100% 20/20 [00:08<00:00,  2.32it/s]\n",
            "100% 20/20 [00:08<00:00,  2.28it/s]\n",
            "100% 20/20 [00:09<00:00,  2.22it/s]\n",
            "100% 20/20 [00:08<00:00,  2.23it/s]\n",
            "100% 50/50 [00:54<00:00,  1.09s/it]\n",
            "100% 50/50 [05:12<00:00,  6.25s/it]\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(ugolcihpzlgoz0a)', <gradio.routes.Request object at 0x7e53f0eb5bd0>, 'Cute plush unicorn, shoujo anime style, soft fluffy texture, big sparkling eyes, pastel colors, winter fairy tale background, snowflakes falling, gentle glowing light, kawaii aesthetic, warm cozy atmosphere, soft shading, smooth vector-like lines, soft gradients, fantasy plush toy, dreamy winter scene.', 'blurry, low quality, deformed, dark, creepy, horror, distorted, extra limbs, missing details, ugly, low resolution, bad anatomy, weird face, disfigured, poorly drawn, overexposed, bad proportions\\n', [], 6, 1, 10, 1080, 1080, True, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 50, 'Euler a', 'Karras', False, '', 0.8, 1409991158, False, -1, 0, 0, 0, ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False, None, None, False, None, None, False, None, None, False, 50) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 847, in process_images\n",
            "        res = process_images_inner(p)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/batch_hijack.py\", line 59, in processing_process_images_hijack\n",
            "        return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 988, in process_images_inner\n",
            "        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 1362, in sample\n",
            "        return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 1461, in sample_hr_pass\n",
            "        decoded_samples = decode_latent_batch(self.sd_model, samples, target_device=devices.cpu, check_for_nans=True)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 632, in decode_latent_batch\n",
            "        sample = decode_first_stage(model, batch[i:i + 1])[0]\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_common.py\", line 76, in decode_first_stage\n",
            "        return samples_to_images_tensor(x, approx_index, model)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_common.py\", line 58, in samples_to_images_tensor\n",
            "        x_sample = model.decode_first_stage(sample.to(model.first_stage_model.dtype))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "        return func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/models/diffusion.py\", line 121, in decode_first_stage\n",
            "        out = self.first_stage_model.decode(z)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/models/autoencoder.py\", line 315, in decode\n",
            "        dec = self.decoder(z, **decoder_kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/modules/diffusionmodules/model.py\", line 732, in forward\n",
            "        h = self.up[i_level].upsample(h)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/modules/diffusionmodules/model.py\", line 67, in forward\n",
            "        x = self.conv(x)\n",
            "            ^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions-builtin/Lora/networks.py\", line 599, in network_Conv2d_forward\n",
            "        return originals.Conv2d_forward(self, input)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
            "        return self._conv_forward(input, self.weight, self.bias)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
            "        return F.conv2d(\n",
            "               ^^^^^^^^^\n",
            "    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.45 GiB. GPU 0 has a total capacity of 14.74 GiB of which 948.12 MiB is free. Process 111607 has 13.81 GiB memory in use. Of the allocated memory 12.31 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "---\n",
            "100% 50/50 [00:56<00:00,  1.12s/it]\n",
            " 80% 40/50 [04:09<01:02,  6.28s/it]Warning: unknown mime-type for \"outputs/txt2img-images\" -- using \"application/octet-stream\"\n",
            "Error: no \"view\" mailcap rules found for type \"application/octet-stream\"\n",
            "/usr/bin/xdg-open: 882: www-browser: not found\n",
            "/usr/bin/xdg-open: 882: links2: not found\n",
            "/usr/bin/xdg-open: 882: elinks: not found\n",
            "/usr/bin/xdg-open: 882: links: not found\n",
            "/usr/bin/xdg-open: 882: lynx: not found\n",
            "/usr/bin/xdg-open: 882: w3m: not found\n",
            "xdg-open: no method available for opening 'outputs/txt2img-images'\n",
            "100% 50/50 [05:11<00:00,  6.24s/it]\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(s6gtifcs261llwj)', <gradio.routes.Request object at 0x7e53f0344710>, 'Cute plush unicorn, shoujo anime style, soft fluffy texture, big sparkling eyes, pastel colors, winter fairy tale background, snowflakes falling, gentle glowing light, kawaii aesthetic, warm cozy atmosphere, soft shading, smooth vector-like lines, soft gradients, fantasy plush toy, dreamy winter scene.', 'blurry, low quality, deformed, dark, creepy, horror, distorted, extra limbs, missing details, ugly, low resolution, bad anatomy, weird face, disfigured, poorly drawn, overexposed, bad proportions\\n', [], 1, 1, 10, 1080, 1080, True, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 50, 'Euler a', 'Karras', False, '', 0.8, 1409991158, False, -1, 0, 0, 0, ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), ControlNetUnit(is_ui=True, input_mode=<InputMode.SIMPLE: 'simple'>, batch_images='', output_dir='', loopback=False, enabled=False, module='none', model='None', weight=1.0, image=None, resize_mode=<ResizeMode.INNER_FIT: 'Crop and Resize'>, low_vram=False, processor_res=-1, threshold_a=-1.0, threshold_b=-1.0, guidance_start=0.0, guidance_end=1.0, pixel_perfect=False, control_mode=<ControlMode.BALANCED: 'Balanced'>, inpaint_crop_input_image=False, hr_option=<HiResFixOption.BOTH: 'Both'>, save_detected_map=True, advanced_weighting=None, effective_region_mask=None, pulid_mode=<PuLIDMode.FIDELITY: 'Fidelity'>, union_control_type=<ControlNetUnionControlType.UNKNOWN: 'Unknown'>, ipadapter_input=None, mask=None, batch_mask_dir=None, animatediff_batch=False, batch_modifiers=[], batch_image_files=[], batch_keyframe_idx=None), False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False, None, None, False, None, None, False, None, None, False, 50) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 847, in process_images\n",
            "        res = process_images_inner(p)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/batch_hijack.py\", line 59, in processing_process_images_hijack\n",
            "        return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 988, in process_images_inner\n",
            "        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 1362, in sample\n",
            "        return self.sample_hr_pass(samples, decoded_samples, seeds, subseeds, subseed_strength, prompts)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 1461, in sample_hr_pass\n",
            "        decoded_samples = decode_latent_batch(self.sd_model, samples, target_device=devices.cpu, check_for_nans=True)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 632, in decode_latent_batch\n",
            "        sample = decode_first_stage(model, batch[i:i + 1])[0]\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_common.py\", line 76, in decode_first_stage\n",
            "        return samples_to_images_tensor(x, approx_index, model)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_common.py\", line 58, in samples_to_images_tensor\n",
            "        x_sample = model.decode_first_stage(sample.to(model.first_stage_model.dtype))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "        return func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/models/diffusion.py\", line 121, in decode_first_stage\n",
            "        out = self.first_stage_model.decode(z)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/models/autoencoder.py\", line 315, in decode\n",
            "        dec = self.decoder(z, **decoder_kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/modules/diffusionmodules/model.py\", line 732, in forward\n",
            "        h = self.up[i_level].upsample(h)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stablediffusion/generative-models/sgm/modules/diffusionmodules/model.py\", line 67, in forward\n",
            "        x = self.conv(x)\n",
            "            ^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions-builtin/Lora/networks.py\", line 599, in network_Conv2d_forward\n",
            "        return originals.Conv2d_forward(self, input)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
            "        return self._conv_forward(input, self.weight, self.bias)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
            "        return F.conv2d(\n",
            "               ^^^^^^^^^\n",
            "    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.45 GiB. GPU 0 has a total capacity of 14.74 GiB of which 948.12 MiB is free. Process 111607 has 13.81 GiB memory in use. Of the allocated memory 12.31 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "---\n",
            "100% 20/20 [00:06<00:00,  2.89it/s]\n",
            "100% 40/40 [00:12<00:00,  3.13it/s]\n",
            "100% 40/40 [00:26<00:00,  1.52it/s]\n",
            "100% 40/40 [00:13<00:00,  3.06it/s]\n",
            "100% 40/40 [00:12<00:00,  3.12it/s]\n",
            "100% 40/40 [00:25<00:00,  1.58it/s]\n",
            "100% 40/40 [00:40<00:00,  1.00s/it]\n",
            "100% 40/40 [02:31<00:00,  3.79s/it]\n",
            "100% 40/40 [00:12<00:00,  3.11it/s]\n",
            "100% 40/40 [00:41<00:00,  1.04s/it]\n",
            "100% 40/40 [00:12<00:00,  3.21it/s]\n",
            "100% 40/40 [00:40<00:00,  1.01s/it]\n",
            "100% 40/40 [00:12<00:00,  3.17it/s]\n",
            "100% 40/40 [00:40<00:00,  1.02s/it]\n",
            "100% 40/40 [00:12<00:00,  3.15it/s]\n",
            "100% 40/40 [00:40<00:00,  1.02s/it]\n",
            "Interrupted with signal 2 in <frame at 0x7e540423e180, file '/usr/lib/python3.11/threading.py', line 331, code wait>\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Start Stable-Diffusion\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from pyngrok import ngrok, conf\n",
        "import re\n",
        "\n",
        "\n",
        "Ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Input your ngrok token if you want to use ngrok server\n",
        "\n",
        "User = \"\" #@param {type:\"string\"}\n",
        "Password= \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional)\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/\n",
        "  !wget -q -O extras.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy/master/modules/extras.py\n",
        "  !wget -q -O sd_models.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy/master/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.11/dist-packages/gradio/blocks.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/\n",
        "\n",
        "  !sed -i 's@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title;model.half()@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/sd_models.py\n",
        "  #!sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/extras.py\n",
        "\n",
        "  !sed -i 's@possible_sd_paths =.*@possible_sd_paths = [\\\"/content/gdrive/{mainpth}/sd/stablediffusion\\\"]@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "  !sed -i 's@\\.\\.\\/@src/@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "  !sed -i 's@src/generative-models@generative-models@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/$mainpth/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\[\"sd_model_checkpoint\"\\]@\\[\"sd_model_checkpoint\", \"sd_vae\", \"CLIP_stop_at_last_layers\", \"inpainting_mask_weight\", \"initial_noise_multiplier\"\\]@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/shared.py\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.11/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''\n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''\n",
        "    sys.stdout.write(line)\n",
        "else:\n",
        "  share='--share'\n",
        "\n",
        "ckptdir=''\n",
        "if os.path.exists('/content/temp_models'):\n",
        "  ckptdir='--ckpt-dir /content/temp_models'\n",
        "\n",
        "try:\n",
        "  model\n",
        "  if os.path.isfile(model):\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt \"$model\" --xformers $auth --disable-console-progressbars --skip-version-check $ckptdir\n",
        "  else:\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt-dir \"$model\" --xformers $auth --disable-console-progressbars --skip-version-check\n",
        "except:\n",
        "   !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --xformers $auth --disable-console-progressbars --skip-version-check $ckptdir"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c684efeff9ec40fb9bd004ede1843b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_a24c736388444ff58305390cd620bd9a",
            "style": "IPY_MODEL_ad87e05eb9a34a20a3d2ca5567e033b4",
            "tooltip": ""
          }
        },
        "a24c736388444ff58305390cd620bd9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad87e05eb9a34a20a3d2ca5567e033b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}